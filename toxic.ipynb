{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "j0VXrXpxffdr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"train.csv\")"
      ],
      "metadata": {
        "id": "sQn4euwlnka1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "y6RqnxuQpsqE",
        "outputId": "0a6d8c24-6ef6-4045-e795-dc35513481e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
              "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
              "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
              "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
              "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  \n",
              "5             0        0       0       0              0  \n",
              "6             1        1       0       1              0  \n",
              "7             0        0       0       0              0  \n",
              "8             0        0       0       0              0  \n",
              "9             0        0       0       0              0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58a2ccfc-32ae-434a-b107-ba51a27e88a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>00025465d4725e87</td>\n",
              "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0002bcb3da6cb337</td>\n",
              "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>00031b1e95af7921</td>\n",
              "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>00037261f536c51d</td>\n",
              "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>00040093b2687caa</td>\n",
              "      <td>alignment on this subject and which are contra...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58a2ccfc-32ae-434a-b107-ba51a27e88a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-58a2ccfc-32ae-434a-b107-ba51a27e88a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-58a2ccfc-32ae-434a-b107-ba51a27e88a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[6]['comment_text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5rMpQZjTpvMd",
        "outputId": "1ab27d45-3aa9-4e20-a075-3fed86f54644"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.columns[2:]].iloc[6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGxVvOgypv9g",
        "outputId": "605f933d-abeb-4069-88ac-3b3021a8af88"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "toxic            1\n",
              "severe_toxic     1\n",
              "obscene          1\n",
              "threat           0\n",
              "insult           1\n",
              "identity_hate    0\n",
              "Name: 6, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aaKp6pnXqiV7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZyClwM0vqiZU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING\n",
        "1. Tokenisation :- converting each word to an identifier so that each word maps towards a number for the sake of NN to understand it"
      ],
      "metadata": {
        "id": "UTLEfKE9nlAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## TOKENISATION\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "5UMYlnTQsXvl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['comment_text']\n",
        "y = df[df.columns[2:]].values"
      ],
      "metadata": {
        "id": "2IkQ7qDotZqS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X80rcj5KwPTF",
        "outputId": "3defa864-26d8-4181-be96-ba0798cd8ba4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((159571,), (159571, 6))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# number of words in the vocabulary\n",
        "MAX_FEATURES = 200000"
      ],
      "metadata": {
        "id": "yx8QgGPowPV4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.arrays import integer\n",
        "# applying tokensisation\n",
        "vectoriser = TextVectorization(max_tokens=MAX_FEATURES, output_sequence_length=2000,output_mode='int')"
      ],
      "metadata": {
        "id": "uYPiq7XgwPYf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "vectoriser.adapt(X.values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrF3SkqZwPbX",
        "outputId": "e0b5ee10-4e95-4929-eb75-c4b68ce26006"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 21.2 s, sys: 1.1 s, total: 22.3 s\n",
            "Wall time: 13.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectoriser.get_vocabulary()"
      ],
      "metadata": {
        "id": "0SoiGBfqwPhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorised_text = vectoriser(X.values)"
      ],
      "metadata": {
        "id": "qJfj7QxywPke"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorised_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHGy1sOawPn6",
        "outputId": "f7cbca5a-01a9-4966-8afc-7b3e7c6f7df6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(159571, 2000), dtype=int64, numpy=\n",
              "array([[  645,    76,     2, ...,     0,     0,     0],\n",
              "       [    1,    54,  2489, ...,     0,     0,     0],\n",
              "       [  425,   441,    70, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [32445,  7392,   383, ...,     0,     0,     0],\n",
              "       [    5,    12,   534, ...,     0,     0,     0],\n",
              "       [    5,     8,   130, ...,     0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATING THE DATASET \n",
        "dataset = tf.data.Dataset.from_tensor_slices((vectorised_text,y))"
      ],
      "metadata": {
        "id": "b45fmEpawPqu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DATASET SEQUENCING THROUTH PIPELINE\n",
        "dataset = dataset.cache()\n",
        "dataset = dataset.shuffle(160000)\n",
        "dataset = dataset.batch(16)\n",
        "dataset = dataset.prefetch(8) "
      ],
      "metadata": {
        "id": "Rtxnk5SM42dD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGIEQupa42k3",
        "outputId": "b2065edc-0eac-41d7-a350-ef55aff47543"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset element_spec=(TensorSpec(shape=(None, 2000), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# taking a peek at the fresh dataset as per batches\n",
        "# with text in the vectorized format, plus all the labels\n",
        "dataset.as_numpy_iterator().next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qtuebe1542nt",
        "outputId": "ae4bf253-4794-46bb-80e7-f179f9c92a8d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[2792,    8,  324, ...,    0,    0,    0],\n",
              "        [ 208, 4324,   41, ...,    0,    0,    0],\n",
              "        [ 797,   27,   91, ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [1321,    3,  298, ...,    0,    0,    0],\n",
              "        [  94,   13,    7, ...,    0,    0,    0],\n",
              "        [  76,  201,   97, ...,    0,    0,    0]]), array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_x, batch_y = dataset.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "2d1gxLOh42qj"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1FI_MMl_E-G",
        "outputId": "ef9b37ce-d2d8-4f83-bed7-c88dc1a38784"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.PrefetchDataset"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# length of dataset in batches of 16\n",
        "len(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJI8Ix13AC4z",
        "outputId": "cef43a16-4447-478e-d541-4bdf5b4748b5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9974"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREATING TRAIN, TEST AND VALIDATION DATA"
      ],
      "metadata": {
        "id": "J2QGIOydAFPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# alloting 70% to training data, 20% to validation and rest to Testing\n",
        "train = dataset.take(int(len(dataset)*0.7))\n",
        "\n",
        "# first skipping the first 70% data and fetching the next 20%\n",
        "validation = dataset.skip(int(len(dataset)*0.7)).take(int(len(dataset)*0.2))\n",
        "\n",
        "# skipping the first 90% data and fetching the rest 10%\n",
        "test = dataset.skip(int(len(dataset)*0.9)).take(int(len(dataset)*0.1))"
      ],
      "metadata": {
        "id": "Rthw2BBLAFwN"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train), len(test), len(validation) # in batches of 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u72V8aqVCU2v",
        "outputId": "aac9e513-151b-4634-bba0-d2beed247df5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6981, 997, 1994)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCvKpgtLCYsZ",
        "outputId": "68e084a8-4b82-4544-a72e-a916297bd652"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset element_spec=(TensorSpec(shape=(None, 2000), dtype=tf.int64, name=None), TensorSpec(shape=(None, 6), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.as_numpy_iterator().next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5Bzea4jNHNo",
        "outputId": "4aec5033-c47e-4ec5-e576-7e1bdb798e1f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   166,     77,   1067, ...,      0,      0,      0],\n",
              "        [    40,    745,      3, ...,      0,      0,      0],\n",
              "        [     5,    123,      2, ...,      0,      0,      0],\n",
              "        ...,\n",
              "        [113882,   1317,     23, ...,      0,      0,      0],\n",
              "        [   125,   7122,   1251, ...,      0,      0,      0],\n",
              "        [    21,      1,   7783, ...,      0,      0,      0]]),\n",
              " array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 0, 0, 1, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [1, 0, 1, 0, 1, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wT9JETlvNTpB"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUILDING THE DEEP NEURAL NETWORK"
      ],
      "metadata": {
        "id": "mCqEri5jQg2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout, Bidirectional, LSTM, Embedding"
      ],
      "metadata": {
        "id": "VlaN2l3tQinA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "9K_BlzbzqwN1"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we use one-hot encoding on words in textual data, we will have a dummy feature for each word, which means 10,000 features for a vocabulary of 10,000 words. This is not a feasible embedding approach as it demands large storage space for the word vectors and reduces model efficiency.\n",
        "\n",
        "Embedding layer enables us to convert each word into a fixed length vector of defined size"
      ],
      "metadata": {
        "id": "KFhuE0i5tXGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the embedding layer\n",
        "model.add(Embedding(MAX_FEATURES+1, 32)) \n",
        "\n",
        "# the GPU acceleration required for the LSTM needs 'tanh'. Although 'relu' can be used as well\n",
        "# Bidirectional allows you to pass informa ion in both direction; particularly on sentences\n",
        "model.add(Bidirectional(LSTM(32, activation = 'tanh')))\n",
        "\n",
        "\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(256, activation = 'relu'))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "\n",
        "# output vlayer\n",
        "model.add(Dense(6, activation = 'sigmoid')) # sigmoid gives us a 0 or 1 output.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "24YA5qkptdGb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='BinaryCrossentropy', optimizer='Adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "2H3M1b7X67uv"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bAlBI4l7IZ6",
        "outputId": "c0d8ed3a-f7b7-4f63-8c01-c55581d61521"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          6400032   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               16640     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 6)                 774       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,491,686\n",
            "Trainable params: 6,491,686\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "classifier = model.fit(train, epochs = 10,validation_data = validation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htQ5G7za7UlV",
        "outputId": "0f797674-5f62-42e0-ed54-b8870f756de4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "6981/6981 [==============================] - 676s 96ms/step - loss: 0.0627 - accuracy: 0.9828 - val_loss: 0.0439 - val_accuracy: 0.9940\n",
            "Epoch 2/10\n",
            "6981/6981 [==============================] - 681s 98ms/step - loss: 0.0460 - accuracy: 0.9935 - val_loss: 0.0419 - val_accuracy: 0.9937\n",
            "Epoch 3/10\n",
            "6981/6981 [==============================] - 680s 97ms/step - loss: 0.0409 - accuracy: 0.9931 - val_loss: 0.0364 - val_accuracy: 0.9942\n",
            "Epoch 4/10\n",
            "6981/6981 [==============================] - 680s 97ms/step - loss: 0.0370 - accuracy: 0.9855 - val_loss: 0.0308 - val_accuracy: 0.9949\n",
            "Epoch 5/10\n",
            "6981/6981 [==============================] - 687s 98ms/step - loss: 0.0327 - accuracy: 0.9932 - val_loss: 0.0295 - val_accuracy: 0.9911\n",
            "Epoch 6/10\n",
            "6981/6981 [==============================] - 681s 98ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 0.0260 - val_accuracy: 0.9943\n",
            "Epoch 7/10\n",
            "6981/6981 [==============================] - 682s 98ms/step - loss: 0.0259 - accuracy: 0.9906 - val_loss: 0.0222 - val_accuracy: 0.9944\n",
            "Epoch 8/10\n",
            "6981/6981 [==============================] - 678s 97ms/step - loss: 0.0238 - accuracy: 0.9750 - val_loss: 0.0198 - val_accuracy: 0.9921\n",
            "Epoch 9/10\n",
            "6981/6981 [==============================] - 674s 97ms/step - loss: 0.0208 - accuracy: 0.9916 - val_loss: 0.0183 - val_accuracy: 0.9945\n",
            "Epoch 10/10\n",
            "6981/6981 [==============================] - 690s 99ms/step - loss: 0.0191 - accuracy: 0.9882 - val_loss: 0.0159 - val_accuracy: 0.9926\n",
            "CPU times: user 1h 54min 45s, sys: 1min 45s, total: 1h 56min 31s\n",
            "Wall time: 1h 56min 33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6obFJON91Kz",
        "outputId": "c48c3626-bc46-46a4-b41b-324a46192c82"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.9827925562858582,\n",
              "  0.9934644103050232,\n",
              "  0.9930615425109863,\n",
              "  0.9854963421821594,\n",
              "  0.993186891078949,\n",
              "  0.9915216565132141,\n",
              "  0.990626335144043,\n",
              "  0.9749588370323181,\n",
              "  0.9915753602981567,\n",
              "  0.9882001280784607],\n",
              " 'loss': [0.06267236173152924,\n",
              "  0.04604221507906914,\n",
              "  0.040858831256628036,\n",
              "  0.03695195913314819,\n",
              "  0.03272239491343498,\n",
              "  0.02933536469936371,\n",
              "  0.02585615962743759,\n",
              "  0.023770475760102272,\n",
              "  0.020837200805544853,\n",
              "  0.019093336537480354],\n",
              " 'val_accuracy': [0.9940133094787598,\n",
              "  0.993699848651886,\n",
              "  0.9942013621330261,\n",
              "  0.9948595762252808,\n",
              "  0.9911296367645264,\n",
              "  0.9942953586578369,\n",
              "  0.9943894147872925,\n",
              "  0.9920699596405029,\n",
              "  0.9944521188735962,\n",
              "  0.9925714731216431],\n",
              " 'val_loss': [0.043946266174316406,\n",
              "  0.0419125072658062,\n",
              "  0.0364437997341156,\n",
              "  0.030812548473477364,\n",
              "  0.029487665742635727,\n",
              "  0.026010029017925262,\n",
              "  0.02223167195916176,\n",
              "  0.019782699644565582,\n",
              "  0.0183291994035244,\n",
              "  0.015903102234005928]}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualisations"
      ],
      "metadata": {
        "id": "6eGHAde4-e1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "uNNDzawW-gRI"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(pd.DataFrame(classifier.history))\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "fMY3wHyq-jmo",
        "outputId": "f65b2eaa-8d29-4864-a96e-b32aabd59a18"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hKCyGffX-wiN"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r4tHq4p4-w09"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAKING PREDICTIONS"
      ],
      "metadata": {
        "id": "wd8dRcoK-xPg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = vectoriser(\"You son of a bitch!\")"
      ],
      "metadata": {
        "id": "gwUAx5hz-zUY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OT5sJCvU_3Vn",
        "outputId": "7a9cbe53-6d6c-420a-d196-166bafaee6ca"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[   46,   168,   462, ...,     0,     0,     0],\n",
              "        [ 1051,   635,   179, ...,     0,     0,     0],\n",
              "        [ 1262,  1062,   880, ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [ 2994,    23,    53, ...,     0,     0,     0],\n",
              "        [  451, 73437, 78345, ...,     0,     0,     0],\n",
              "        [ 1619,   430,    11, ...,     0,     0,     0]]),\n",
              " array([[0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0]]))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_x,batch_y = test.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "GIx88MRMfXSh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "prediction = model.predict(batch_x).astype(int) #input should be a numpy array"
      ],
      "metadata": {
        "id": "IsDN7A8RASch"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking a look at the predictions\n",
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAwHjtsjBo_E",
        "outputId": "d2b4bd18-4dc4-4523-c4d2-7e67fff2ca4c"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KKj0zLPCfu47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL EVALUATION"
      ],
      "metadata": {
        "id": "RhoUi2MLfycB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
      ],
      "metadata": {
        "id": "e4Tfmv2QfzxE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.arrays.categorical import CategoricalAccessor\n",
        "precision = Precision()\n",
        "recall = Recall()\n",
        "accuracy = CategoricalAccuracy()"
      ],
      "metadata": {
        "id": "aBBlCWJWf5Zs"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "for batch in test.as_numpy_iterator():\n",
        "  X_test, y_test = batch\n",
        "  y_predict = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Flattening the predictions\n",
        "  y_test = y_test.flatten()\n",
        "  y_predict = y_predict.flatten()\n",
        "\n",
        "\n",
        "  # updating the metrics\n",
        "  precision.update_state(y_test,y_predict)\n",
        "  recall.update_state(y_test,y_predict)\n",
        "  accuracy.update_state(y_test,y_predict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJynu3r2gK9D",
        "outputId": "aa82cfb8-681f-4c97-879c-e32b0def9d83"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 28s, sys: 2.33 s, total: 1min 30s\n",
            "Wall time: 1min 29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Precision: {precision.result().numpy()}, Recall:{recall.result().numpy()}, Accuracy:{accuracy.result().numpy()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3qDbCWpiwkj",
        "outputId": "d5f329d9-70c1-42eb-8303-3db753316ca3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9315667152404785, Recall:0.9080329537391663, Accuracy:0.5185556411743164\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIO APPLICATION IMPLEMENTATION ( extra )"
      ],
      "metadata": {
        "id": "QJ9nFFUcjA7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio jinja2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFcPNoCajGm5",
        "outputId": "332b1201-5e0f-44e3-dee4-e85d202a61e0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gradio\n",
            "  Downloading gradio-3.0.5-py3-none-any.whl (5.1 MB)\n",
            "\u001b[K     || 5.1 MB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (2.11.3)\n",
            "Collecting ffmpy\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "Collecting fastapi\n",
            "  Downloading fastapi-0.78.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     || 54 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Collecting markdown-it-py[linkify,plugins]\n",
            "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[K     || 84 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.14.1-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     || 2.0 MB 12.3 MB/s \n",
            "\u001b[?25hCollecting python-multipart\n",
            "  Downloading python-multipart-0.0.5.tar.gz (32 kB)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     || 1.1 MB 49.5 MB/s \n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.17.6-py3-none-any.whl (53 kB)\n",
            "\u001b[K     || 53 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Collecting orjson\n",
            "  Downloading orjson-3.6.8-cp37-cp37m-manylinux_2_24_x86_64.whl (253 kB)\n",
            "\u001b[K     || 253 kB 73.6 MB/s \n",
            "\u001b[?25hCollecting paramiko\n",
            "  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n",
            "\u001b[K     || 212 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Collecting analytics-python\n",
            "  Downloading analytics_python-1.4.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2) (2.0.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     || 144 kB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     || 271 kB 75.8 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     || 94 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading backoff-1.10.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting monotonic>=1.5\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2022.5.18.1)\n",
            "Collecting starlette==0.19.1\n",
            "  Downloading starlette-0.19.1-py3-none-any.whl (63 kB)\n",
            "\u001b[K     || 63 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     || 11.1 MB 52.3 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.1-py3-none-any.whl (80 kB)\n",
            "\u001b[K     || 80 kB 10.0 MB/s \n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.1-py3-none-any.whl (10 kB)\n",
            "Collecting linkify-it-py~=1.0\n",
            "  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\n",
            "Collecting mdit-py-plugins\n",
            "  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[K     || 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting uc-micro-py\n",
            "  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.1)\n",
            "Collecting cryptography>=2.5\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     || 4.0 MB 50.2 MB/s \n",
            "\u001b[?25hCollecting pynacl>=1.0.1\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[K     || 856 kB 58.9 MB/s \n",
            "\u001b[?25hCollecting bcrypt>=3.1.3\n",
            "  Downloading bcrypt-3.2.2-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (62 kB)\n",
            "\u001b[K     || 62 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt>=3.1.3->paramiko->gradio) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko->gradio) (2.21)\n",
            "Collecting asgiref>=3.4.0\n",
            "  Downloading asgiref-3.5.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n",
            "Collecting h11>=0.8\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     || 58 kB 7.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpy, python-multipart\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=7ca0c477e9cc0ce02fdb716b88fe4c2ce1c0225975367ec51e51943a6bcb6854\n",
            "  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=473d35912ab9a3180e9985b242523e056585a399d7a620795fa6f0bc2574e9da\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\n",
            "Successfully built ffmpy python-multipart\n",
            "Installing collected packages: sniffio, mdurl, uc-micro-py, multidict, markdown-it-py, frozenlist, anyio, yarl, starlette, pynacl, pydantic, monotonic, mdit-py-plugins, linkify-it-py, h11, cryptography, bcrypt, backoff, asynctest, async-timeout, asgiref, aiosignal, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, ffmpy, fastapi, analytics-python, aiohttp, gradio\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 analytics-python-1.4.0 anyio-3.6.1 asgiref-3.5.2 async-timeout-4.0.2 asynctest-0.13.0 backoff-1.10.0 bcrypt-3.2.2 cryptography-37.0.2 fastapi-0.78.0 ffmpy-0.3.0 frozenlist-1.3.0 gradio-3.0.5 h11-0.13.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.0 mdurl-0.1.1 monotonic-1.6 multidict-6.0.2 orjson-3.6.8 paramiko-2.11.0 pycryptodome-3.14.1 pydantic-1.9.1 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 sniffio-1.2.0 starlette-0.19.1 uc-micro-py-1.0.1 uvicorn-0.17.6 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gradio"
      ],
      "metadata": {
        "id": "Bph1ic9ojSX1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('toxicity.h5')"
      ],
      "metadata": {
        "id": "1bu1g5A1jVhD"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_comment(comment):\n",
        "    vectorized_comment = vectoriser([comment])\n",
        "    results = model.predict(vectorized_comment)\n",
        "    \n",
        "    text = ''\n",
        "    for idx, col in enumerate(df.columns[2:]):\n",
        "        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n",
        "    \n",
        "    return text"
      ],
      "metadata": {
        "id": "obRbfu_pjXU2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gradio.Interface(fn=score_comment, \n",
        "                         inputs=gradio.inputs.Textbox(lines=2, placeholder='Comment to score'),\n",
        "                        outputs='text')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGD1hQHnkKo7",
        "outputId": "57af2c4b-a3e0-4994-8608-fd8808bb350f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "-yWSAxDmkNdA",
        "outputId": "bf4c6e34-a2a0-468f-e074-6ea38eb55e79"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://56568.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7fb5e41f0f90>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"900\"\n",
              "            height=\"500\"\n",
              "            src=\"https://56568.gradio.app\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7fb6d052e610>,\n",
              " 'http://127.0.0.1:7860/',\n",
              " 'https://56568.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IypMTCZjkVhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}